{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER IV\n",
    "\n",
    "# Systems of Linear Equations\n",
    "&copy; Harishankar Manikantan, maintained on GitHub at [hmanikantan/ECH60](https://github.com/hmanikantan/ECH60) and published under an [MIT license](https://github.com/hmanikantan/ECH60/blob/master/LICENSE).\n",
    "\n",
    "Return to [Course Home Page](https://hmanikantan.github.io/ECH60/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[(4.1) Elimination Methods](#lineq)**\n",
    "*  [Linear Systems and Computational Cost](#cost1) <br> \n",
    "*  [Gauss Elimination](#Gauss) <br> \n",
    "*  [Pivoting: choosing the right row](#GaussPiv) <br> \n",
    "*  [Gauss-Jordan: Gauss on steroids!](#GaussJ) <br> \n",
    "*  [LU Decomposition](#LU) <br> \n",
    "*  [Computational Cost Revisited](#cost) <br>\n",
    "\n",
    "**[(4.2) Inbuilt Python Routines](#inbuilt)**\n",
    "*  [Solving Linear Systems: linalg.solve](#solve) <br> \n",
    "*  [Fast and Easy Linear Algebra](#linalg) <br> \n",
    "\n",
    "\n",
    "**[Practice problems](#exer)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lineq'></a>\n",
    "\n",
    "\n",
    "\n",
    "## (3.3) Elimination Methods\n",
    "\n",
    "Systems of linear algebraic equations arise in every aspect of engineering calculations. For example, the 'response' and forcing' are linearly realted in heat flow, porous media percolation, electrical circuits, electromagnetism, elasticity theory etc. More generally, numerical methods in later parts of the course (with regression, deifferential equations, etc) rely on being able to 'invert' or solve a set of couple algebraic equations. In many problems, the memory and time requirements can be high (although this might not be immediately obvious with most modern computers), and efficient fast solutions of linear systems can be key to optimally solving these problems.\n",
    "\n",
    "<a id='cost1'></a>\n",
    "\n",
    "\n",
    "\n",
    "### Linear Systems and Computational Cost\n",
    "\n",
    "The standard notation for a system of $n$ equations with $n$ unknowns is as follows (we will use python's numbering system going from 0 to n-1 to avoid confusion):\n",
    "\n",
    "$$\\begin{matrix} A_{00}x_0 + A_{01}x_1 + ... + A_{0,n-1}x_{n-1} = b_0\\\\A_{10}x_0 + A_{11}x_1 + ... + A_{1,n-1}x_{n-1} = b_1 \\\\ .\\\\.\\\\.\\\\A_{n-1,0}x_0 + A_{n-1,1}x_1 + ... + A_{n-1,n-1}x_{n-1} = b_{n-1}\\end{matrix}$$\n",
    "\n",
    "Here, $x_0, x_1, ..., x_{n-1}$ are the n unknown quantities and the coefficients $A_{ij}$ and constants $b_j$ are all known. In matrix notation, this can be rewritten as \n",
    "\n",
    "$$\\begin{bmatrix} A_{00} & A_{01} & ... & A_{0,n-1}\\\\A_{10} & A_{11} & ... & A_{1,n-1} \\\\ . & & &. \\\\. & & \\ddots&. \\\\.& & & .\\\\A_{n-1,0} & A_{n-1,1} & ... & A_{n-1,n-1}\\end{bmatrix} \\begin{bmatrix} x_0 \\\\ x_1 \\\\ .\\\\.\\\\.\\\\ x_{n-1}  \\end{bmatrix}= \\begin{bmatrix} b_0 \\\\ b_1 \\\\ .\\\\.\\\\.\\\\ b_{n-1}  \\end{bmatrix}$$\n",
    "\n",
    "Or, in short hand, ${\\bf A x =b}$. Here, ${\\bf A}$ is a $n \\times n$ matrix with all entries known, ${\\bf b}=(b_0, b_1, ..., b_{n-1}) $ is a column vector with all entries known, and ${\\bf x}=(x_0, x_1, ..., x_{n-1} )$ is a column vector of the unknowns we are after.\n",
    "\n",
    "We know from linear algebra that the solution can be directly obtained by premultipying both side with the matrix inverse of ${\\bf A}$ and noting that ${\\bf A A}^{-1}={\\bf I} $, where ${\\bf I}$ is the identity matrix. This means that ${\\bf x = A}^{-1}{\\bf b}$, and so computing the matrix inverse and performing a matrix-vector operation should give us the solution.\n",
    "\n",
    "However, calculating the inverse of a matrix can be a computationally expensive operation if the matrix is large. Evaluating the determinant of a 2x2 matrix requires 2 multiplication operations and a subtraction. For a 3x3 matrix, the cost is at least 3 times that (associated with picking a row or a column, and evaluating the 2x2 submatrix determinant for each). For a 4x4 matrix, it's at least 4 times that of a 3x3. Working up, the pen-and-paper formula (called the Laplace expansion) of calculating the determinant of a $n \\times n$ matrix is at least $n!$ calculations (plus additions/subtractions etc). And there are even more associated with determining the inverse and then performing the multiplication with the RHS. When we get to numerical solutions of differential equations, we will encounter matrices with hundreds if not thousands of rows and columns, and this operation can be prohibitively long. \n",
    "\n",
    "Fortunately, entire families of 'elimination' algorithms help us circumvent the direct inversion of a matrix. The most common way to solve such a system is by manipulating the system to an equivalent system which is more easily solved. The classic methods that use this trick are Gauss elimination, LU decomposition, and more specific versions of either. Although python has inbuilt routines to efficiently calculate inverses (and we will see these later), it's valuable to learn the algorithmic steps in obtaining the solution to such a standard linear algebraic problem. \n",
    "\n",
    "\n",
    "\n",
    "<a id='Gauss'></a>\n",
    "\n",
    "\n",
    "\n",
    "### Gauss elimination\n",
    "\n",
    "Gauss elimination is the most common and direct way to solve a matrix system. It involves a series of algortihmic manipulations that convert the matrix to a triangular (or 'echelon') form, and then back-substitutes equation by equation to get the final solution. In the following, we will see every step in action, which will help us build the whole Guass elimination code in the end.\n",
    "\n",
    "Consider the system of 3 equations (so n=3):\n",
    "$$\\begin{matrix} 4x_0 -2x_1 + x_2 = 11\\\\-2x_0 + 4x_1 -2x_2 = -16 \\\\x_0 -2x_1 +4x_2 = 17\\end{matrix}$$\n",
    "In matrix form, this system is:\n",
    "$$\\begin{bmatrix} 4 & -2  & 1 \\\\-2 & 4 & -2 \\\\1 & -2 & 4 \\end{bmatrix} \\begin{bmatrix} x_0 \\\\ x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 11 \\\\ -16 \\\\ 17 \\end{bmatrix}$$\n",
    "\n",
    "The objective of Gauss elimination is to somehow convert this matrix to a triangular form using linear transformations of the original matrix, so it looks like\n",
    "\n",
    "$$\\begin{bmatrix} A_{00} & A_{01}  & A_{02} \\\\0 & A_{11} & A_{12} \\\\0 & 0 & A_{22} \\end{bmatrix} \\begin{bmatrix} x_0 \\\\ x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} b_0 \\\\ b_1 \\\\ b_2 \\end{bmatrix}$$\n",
    "\n",
    "Note that $b_0$, $b_1$, and $b_2$ are not necessarily same as the original matrix after this conversion. The advantage of this form is evident if we write the converted system back in equation form:\n",
    "$$\\begin{matrix} A_{00}x_0 +A_{01}x_1 + A_{02}x_2 = b_0\\\\A_{11}x_1 +A_{12}x_2 = b_1 \\\\A_{22}x_2 = b_2\\end{matrix}$$\n",
    "\n",
    "Once in this form, solving for $x_2$ is straightforward: $x_2=b_2/A_{22}$. Once $x_2$ is known, solving for $x_1$ is straightforward: $x_1=\\left(b_1-A_{12}x_2 \\right)/A_{11}$. With $x_2$ and $x_1$ known, solving for $x_0$ is straightforward: $x_0=\\left(b_0-A_{01}x_1 - A_{02}x_2\\right)/A_{00}$. For a larger matrix, these steps continue further upward until all unknowns are determined. This process is called back-substitution.\n",
    "\n",
    "So, how do we go about converting any general matrix to this convenient triangular form. It is useful to construct an *augmented* matrix that combines ${\\bf A}$ and ${\\bf b}$ which would then look like:\n",
    "\n",
    "$$\\begin{bmatrix} 4 & -2  & 1 &: & {\\it 11} \\\\-2 & 4 & -2 &: & {\\it -16} \\\\1 & -2 & 4 &: & {\\it 17}\\end{bmatrix} $$\n",
    "\n",
    "Here, the dots and the italicization remind us that the last column is, in fact, the right hand side of the original equations. Let's first import numpy as make an array of this augmented matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.  -2.   1.  11.]\n",
      " [ -2.   4.  -2. -16.]\n",
      " [  1.  -2.   4.  17.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "Aug=np.array([[4.,-2.,1.,11.],[-2.,4.,-2.,-16.],[1.,-2.,4.,17.]])\n",
    "\n",
    "# use dots to force entries to be floats (or alternatively set the dtype option)\n",
    "# Aug=np.array([[4,-2,1,11],[-2,4,-2,-16],[1,-2,4,17]],dtype=float)\n",
    "\n",
    "print(Aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the last column is the right hand side, and is not part of the matrix ${\\bf A}$. The objective is to get zeros in the lower triangular part of the $3 \\times 3$ matrix using linear combinations of any rows. Let's start with the second row. We need to eliminate the first entry in that row (currently -2) and make it a zero. One way to do this is to multiply the first row with 0.5, add it to the second row, and let the result replace the second row. In pseudocode, this would read: $$\\text{row}_1 = \\text{row}_1 + 0.5 (\\text{row}_0)$$\n",
    "The unchanged first row is then called the 'pivot'. In terms of array manipulation, this would be equivalent t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.   -2.    1.   11. ]\n",
      " [  0.    3.   -1.5 -10.5]\n",
      " [  1.   -2.    4.   17. ]]\n"
     ]
    }
   ],
   "source": [
    "Aug[1,:]=Aug[1,:]+0.5*Aug[0,:]\n",
    "print(Aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the final column, corresponding to the right hand side, is also simultaneously changing in this augmented form. Now let's clear out the first entry in the last row as well, which is currently 1. The transformation that makes this 0 is $$\\text{row}_2 = \\text{row}_2 - 0.25 (\\text{row}_0)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.    -2.     1.    11.  ]\n",
      " [  0.     3.    -1.5  -10.5 ]\n",
      " [  0.    -1.5    3.75  14.25]]\n"
     ]
    }
   ],
   "source": [
    "Aug[2,:]=Aug[2,:]-0.25*Aug[0,:]\n",
    "print(Aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are doing good so far. For this matrix, the next step is to move to the second row as our 'pivot' and use it to eliminate leading 0s in every row below it. Here, that means eliminating the -1.5 in the third row using $$\\text{row}_2 = \\text{row}_2 + 0.5 (\\text{row}_1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.   -2.    1.   11. ]\n",
      " [  0.    3.   -1.5 -10.5]\n",
      " [  0.    0.    3.    9. ]]\n"
     ]
    }
   ],
   "source": [
    "Aug[2,:]=Aug[2,:]+0.5*Aug[1,:]\n",
    "print(Aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we have it! The original $3\\times 3$ is in an upper triangular form, and the corresponding RHS is the fourth column of `Aug`. The corresponding modified equation system is\n",
    "\n",
    "$$\\begin{matrix} 4x_0 -2x_1 +x_2 = 11\\\\3 x_1 -1.5x_2 = -10.5 \\\\3x_2 = 9\\end{matrix}$$\n",
    "\n",
    "The backsubstitution phase is then straigtforward. Start with the last row of `Aug` to get $x_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first define an array of zeros for x\n",
    "x=np.zeros(3)\n",
    "\n",
    "# x2 from last row\n",
    "x[2]=Aug[2,3]/Aug[2,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then sequentially work upward to uncover $x_1$ and then $x_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -2.  3.]\n"
     ]
    }
   ],
   "source": [
    "# solve for x1\n",
    "x[1]=(Aug[1,3]-Aug[1,2]*x[2])/Aug[1,1]\n",
    "\n",
    "# then solve for x0\n",
    "x[0]=(Aug[0,3]-Aug[0,1]*x[1]-Aug[0,2]*x[2])/Aug[0,0]\n",
    "\n",
    "# results!\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's our solution! More generally, we would like our code to figure out for itself what the multipliers (+0.5, -0.25, +0.5 above) in each step were. These multiplier constants are picked so that the entry in the 'current' row becomes zero when added to the scaled 'pivot' row. So we need multiplier constants that are the negative of the entry in the same column in the 'current' row divided by the entry in the 'pivot' row.\n",
    "\n",
    "In the example above, the first multiplier +0.5 was simply `-Aug[1,0]/Aug[0,0]` or -(-2)/4. Using this logic, we can construct a more general Gauss elimination algorithm in one shot that works for any $3 \\times 3$ matrix, and it would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -2.  3.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "Aug=np.array([[4,-2,1,11],[-2,4,-2,-16],[1,-2,4,17]],dtype=float)\n",
    "x=np.zeros(3)\n",
    "\n",
    "# find multiplier to eliminate A10, replace row\n",
    "mult_1=-Aug[1,0]/Aug[0,0]\n",
    "Aug[1,:]=Aug[1,:]+mult_1*Aug[0,:]\n",
    "\n",
    "# find multiplier to eliminate A20, replace row\n",
    "mult_2=-Aug[2,0]/Aug[0,0]\n",
    "Aug[2,:]=Aug[2,:]+mult_2*Aug[0,:]\n",
    "\n",
    "# find multiplier to eliminate A21, replace row\n",
    "mult_3=-Aug[2,1]/Aug[1,1]\n",
    "Aug[2,:]=Aug[2,:]+mult_3*Aug[1,:]\n",
    "\n",
    "# back-substitute\n",
    "x[2]=Aug[2,3]/Aug[2,2]\n",
    "x[1]=(Aug[1,3]-Aug[1,2]*x[2])/Aug[1,1]\n",
    "x[0]=(Aug[0,3]-Aug[0,1]*x[1]-Aug[0,2]*x[2])/Aug[0,0]\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the augmented matrix above to determine solutions to the following system: $$\\begin{matrix} 8x_0 -6x_1 + 2x_2 = 28\\\\-4x_0 + 11x_1 -7x_2 = -40 \\\\4x_0 -7x_1 +6x_2 = 33\\end{matrix}$$\n",
    "\n",
    "Let's build up in generality. Given the ${\\bf A}$ matrix and the the RHS column vector ${\\bf b}$, the augmented matrix can be constructed using the `hstack` (horizontal stack) command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4. -2.  1.]\n",
      " [-2.  4. -2.]\n",
      " [ 1. -2.  4.]]\n",
      "[[ 11]\n",
      " [-16]\n",
      " [ 17]]\n",
      "[[  4.  -2.   1.  11.]\n",
      " [ -2.   4.  -2. -16.]\n",
      " [  1.  -2.   4.  17.]]\n"
     ]
    }
   ],
   "source": [
    "# 3 by 3 matrix\n",
    "A=np.array([[4,-2,1],[-2,4,-2],[1,-2,4]],dtype=float)\n",
    "print(A)\n",
    "\n",
    "# 3 by 1 column vector\n",
    "b=np.array([[11],[-16],[17]])\n",
    "print(b)\n",
    "\n",
    "# horizontally stack\n",
    "Aug=np.hstack((A,b))\n",
    "print(Aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful to stack the same matrix with multiple possible right-hand sides. Now you have all the ingredients to create a function that will take a $3\\times 3$ matrix and a $3 \\times 1$ vector as inputs, and return the solution of the system as the output. Make this function as an exercise! We will use it over and over again.\n",
    "\n",
    "We will often run into matrices and linear system much bigger than n=3. So the last step in generalizing Gauss elimination is carefully extending the logic to arbitrary matrix size. This requires the additional steps of finding the size of the matrix and running loops to do all the step above, but the core idea is the same. The following algorithmic steps will do the triangular elimination:\n",
    "\n",
    "* determine the size of the system n\n",
    "* stack the RHS\n",
    "* start with the first row as the pivot row\n",
    "* eliminate the first column in every row under the first using the row replacement trick\n",
    "* move to the second row as the pivot row\n",
    "* eliminate the second column in every row under the second using the row replacement trick <br>\n",
    ". <br>\n",
    ". <br>\n",
    ". <br>\n",
    "* repeat until last but one row is the pivot row\n",
    "\n",
    "Notice that this requires a loop to traverse the 'pivot' rows and an loop within a loop (an 'inner' or 'nested' loop) to traverse every row below the pivot row at each step.\n",
    "\n",
    "The following code does this for any matrix with n rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Aug and n first\n",
    "n=len(Aug)\n",
    "for i in range(n-1):\n",
    "    for j in range(i+1,n):\n",
    "        mult=-Aug[j,i]/Aug[i,i]\n",
    "        Aug[j,:]+=mult*Aug[i,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the augmented matrix from one of the examples above (with n=3) to verify that this piece of code does indeed eliminate all lower traingular elements.\n",
    "\n",
    "Then try again with a bigger matrix! Generate an arbitrary matrix filled with random numbers (see tutorial 2) with 10 rows and columns. See if this works.\n",
    "\n",
    "Now that we have a triangular matrix $U$ and a modified RHS $c$ tha can be extracted from the modified augmented matrix, the backsubstitution is straightforward. Comparing with the 3 equation system above, the general formula for $x_i$ where $i$ is between 0 and n-1 working from the bottom up is \n",
    "$$x_i=\\left(c_i - \\sum_{j=i+1}^{n-1} U_{ij}x_j \\right) \\bigg/ U_{ii} $$\n",
    "\n",
    "This has to start from the last row ($i=n-1$) and work up to the first ($i=0$). Recognize that $U$ and $c$ are just parts of the augmnented matrix result from the triangulation. So the corresponding code is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a 'blank' x with zeros\n",
    "x=np.zeros(n)\n",
    "\n",
    "for i in range(n-1,-1,-1): # justify why the -1 here?\n",
    "    x[i]=Aug[i,-1]         # and what about the -1 here?\n",
    "    for j in range(i+1,n):\n",
    "        x[i]-=Aug[i,j]*x[j]\n",
    "    x[i]/=Aug[i,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that this is conjunction with the triangulation code does solve both the $3\\times 3$ matrices above.\n",
    "\n",
    "Now you are ready to write a full function that takes a general square matrix, a column vector, and does all of the following in one shot. **Create this function for future use!** This should do the following:\n",
    "* determine n using `len(b)`\n",
    "* stack to create an augmented matrix\n",
    "* triangulate (do a zero check)\n",
    "* backsubstitute\n",
    "* return the solution of the system!\n",
    "\n",
    "There are a few more optimization one can do. For example, we do not need to create a new variable `x`. We can econonomize on memory storage by simply overwriting the RHS column vector (since it has already taken up computer memory) or the last column of our augmented matrix with our result, and then return it as the solution. Also, we can replace the inner loop in the back-substitution phase with a `dot` operation. Further, if an entry is already zero, we dont need to eliminate it because it's zero to begin with! So we can just skip that replacement step: one way to do this is to put an `if` condition and run the replacement lines only if `A[j,i]!=0.` (notice the float 0. and not the integer 0). And, finally, we can also do all these steps directly on ${\\bf A}$ _and_ ${\\bf b}$ without even creating the augmented matrix: you just have to carefully do all the steps for the corresponding column vector as well. Try any of these enhancements if you are adventurous and verify your result with sample matrices with each change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function Gauss(A,b)\n",
    "# input A: n x n matrix\n",
    "# input b: n x 1 column vector\n",
    "# return as output: n x 1 column vector solution of system Ax=b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='GaussPiv'></a>\n",
    "\n",
    "\n",
    "\n",
    "### Pivoting: choosing the right row\n",
    "\n",
    "Once you have your 'packaged' function `Gauss` ready, we can explore an important situation where the simple Gauss elimination fails. Consider the following system of three variables:\n",
    "$$\\begin{matrix} 2x_0 -x_1= 1\\\\-x_0 + 2x_1 -x_2 = 0 \\\\-x_1 +x_2 = 0\\end{matrix}$$\n",
    "Solving this using your `Gauss` function (the following code assumes that a function of that name has been created and executed before this):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create matrix and RHS vector\n",
    "C=np.array([[2,-1,0],[-1,2,-1],[0,-1,1]],dtype=float)\n",
    "d=np.array([[1],[0],[0]],dtype=float)\n",
    "\n",
    "# solve\n",
    "Gauss(C,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is $(1,1,1)$. Now, run the same system but with the order of rows changed:\n",
    "$$\\begin{matrix} -x_1 +x_2 = 0\\\\2x_0 -x_1= 1\\\\-x_0 + 2x_1 -x_2 = 0 \\end{matrix}$$\n",
    "The solution should be the same, because the equations are the same and clearly have a unique solution. But try changin C and d above to this order and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harishankar/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \n",
      "/Users/harishankar/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in multiply\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/harishankar/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan],\n",
       "       [nan],\n",
       "       [nan]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same system, row order changed\n",
    "C=np.array([[0,-1,1],[2,-1,0],[-1,2,-1]],dtype=float)\n",
    "d=np.array([[0],[1],[0]],dtype=float)\n",
    "\n",
    "# solve\n",
    "Gauss(C,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get error warnings. And the results are `nan`, which is computer lingo for Not A Number.\n",
    "\n",
    "If you think carefully, the only (seemingly harmless) change between the two cases is that the second version has a matrix with a 0 in the diagonal. And Gauss elimination repeatedly uses a division by diagonal elements in the pivot row to determine the 'multiplier' for every row below it. And this division by zero gives the error.\n",
    "\n",
    "This is where choosing the pivot row becomes crucial. We have to be prepared for a matrix to have terms on the diagonal and preemptively avoid this error. The trick then is to first check if the diagonal entry in the reference or pivot row is 0, and if it is, swap that row with any row beloe it that does not have a zero along that column. And the corresponding RHS would swap too. The system of equations remains the same, but the order of pivoting changes. Try this as a practice problem, and develop a modified version of Gauss elimination called `GaussPiv(A,b)`. Then \n",
    "\n",
    "\n",
    "This is where choosing the pivot row becomes crucial. The trick then is to first check if the diagonal entry in the reference or pivot row is 0, and if it is, swap that row with any row below it that does not have a zero along that column. Try this as a practice problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function GaussPiv(A,b)\n",
    "# input A: n x n matrix\n",
    "# input b: n x 1 column vector\n",
    "# return as output: n x 1 column vector solution of system Ax=b\n",
    "# must use a pivot row swap if diagonal entry is 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, solve the troublesome system from before using your `GaussPiv` function (the following code assumes that a function of that name has been executed before this):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same system, row order changed\n",
    "C=np.array([[0,-1,1],[2,-1,0],[-1,2,-1]],dtype=float)\n",
    "d=np.array([[0],[1],[0]],dtype=float)\n",
    "\n",
    "# solve using pivoted version\n",
    "GaussPiv(C,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you swap your pivot row correctly, you should not find an error. And the solution should be the same as before!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='GaussJ'></a>\n",
    "\n",
    "\n",
    "\n",
    "### Gauss-Jordan: Gauss elimination on steroids!\n",
    "\n",
    "A common variant of Gauss elimination is the Gauss-Jordan method. Here, the idea is that you don't just eliminate the lower triangular entries, but keep going and do the same for the upper triangle as well. That would leave us with just the diagonal entries being non-zero. Additionally, if we normalize the pivot row with the diagonal entry (meaning divide the entire row by the diagonal entry), the final resultant matrix will only have diagonal entries and all of them will be 1. This is the identity matrix!\n",
    "\n",
    "In other words, the aim of the Gauss-Jordan methdod is to get the augmented system to looks like this (shown here for a $3 \\times 3$ system):\n",
    "$$\\begin{bmatrix} 1 & 0  & 0 &: & {\\it c_0} \\\\0 & 1 & 0 &: & {\\it c_1} \\\\0& 0 &  1&: & {\\it c_2}\\end{bmatrix} $$\n",
    "\n",
    "Then, reverting back to the equation form tells us that this simply means $x_0=c_0$, $x_1=c_1$, and $x_2=c_2$. So the Gauss-Jordan method avoids having to back-substitute by going on with row replacements until you obtain a diagonal matrix. You can do this with minor modifications to your pivoted Gauss code above. Make this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function GaussJ(A,b) for Gauss-Jordan elimination\n",
    "# input A: n x n matrix\n",
    "# input b: n x 1 column vector\n",
    "# return as output: n x 1 column vector solution of system Ax=b\n",
    "# must use a pivot row swap if diagonal entry is 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='LU'></a>\n",
    "\n",
    "\n",
    "\n",
    "### LU Decomposition\n",
    "\n",
    "There are other methods along the same vein as Gauss elimination with slight differences, advantages and disadvantages. And we can adapt these methods to do more genral linear algebraical opertaions like caclculating inverses and determinants. We will explore some examples in the practice problems. For others, see the recommended reading book. The differences between methods is mostly imperceivable for our current uses, but even microseconds of speed gain in computation can add up if you have 1000 x 1000 matrices, or if you have to do repeated matrix calculations as a function of time etc.  \n",
    "\n",
    "A common one is the LU decomposition which finds a separate lower triangular matrix ${\\bf L}$ and upper triangular matrix ${\\bf U}$ such that ${\\bf LU}={\\bf A}$. Then, our matrix system ${\\bf Ax}={\\bf b}$ can be rewritten as \n",
    "\n",
    "$${\\bf LUx}={\\bf b} \\quad \\Rightarrow \\quad {\\bf L y}={\\bf b} \\quad \\& \\quad {\\bf Ux}={\\bf y}.$$\n",
    "\n",
    "The idea then is that ${\\bf y}$ can be solved by forward-substituting using ${\\bf L}$ and ${\\bf b}$, and then ${\\bf x}$ can be determined by back-substituting using ${\\bf U}$ and ${\\bf y}$. Using what we know of Gauss elimination, we can easily develop an LU routine (see the reference by Jaan Kiusalaas for an example code).\n",
    "\n",
    "While this may seem like twice the effort, the benefit is that the LU decomposition works only on the matrix ${\\bf A}$ and not on the augmented matrix ${\\bf A}|{\\bf b}$. So the LU operation is independent of ${\\bf b}$. This is good if we need to solve the same equation system for a changing right-hand side (e.g. a time varying RHS, a different forcing etc). By decoupling the RHS, the LU decomposition is beneficial in these cases because the same ${\\bf L}$ and ${\\bf U}$ can be used for different column values ${\\bf b}$, thereby saving net computational effort. This is unlike the standard Gauss methods where every ${\\bf b}$ has to be manipulated separately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a id='cost'></a>\n",
    "\n",
    "\n",
    "\n",
    "### Computational Cost\n",
    "\n",
    "\n",
    "This brings us to a few comments on computational 'cost', which is a measure of the time required by a processor to perform a calculation. Why did we not develop an algorithm to first determine the inverse of a matrix and then simply multiply it with the RHS? After all, isn't that what we learn in linear algebra classes? The inverse can be calculated using the standard formula (for each element, find the submatrix, find determinant, etc etc...). \n",
    "\n",
    "The reason is that matrix manipulations and inversions are notoriously 'expensive' monstrous operations. Evaluating the determinant of a 2x2 matrix requires 2 multiplication operations and a subtraction. For a 3x3 matrix, the cost is at least 3 times that (associated with picking a row or a column, and evaluating the 2x2 submatrix determinant for each). For a 4x4 matrix, it's at least 4 times that of a 3x3. Working up, the pen-and-paper formula (called the Laplace expansion) of calculating the determinant of a $n \\times n$ matrix is at least $n!$ calculations (plus additions/subtractions etc). And there are even more associated with determining the inverse and then performing the multiplication with the RHS.\n",
    "\n",
    "By contrast, Gauss elimination (and it's relatives: Gauss-Jordan, LU, etc) requires an outer loop through n entries, an inner loop through n or fewer entries, and row substitutions of at most n entries, giving a total of around $n^3$ operations. Although these are estimates of the number of operations, we can get a good sense of how they scale by plotting and comparing $n^3$ and $n!$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as sp # for easy factorial in vectorized form\n",
    "\n",
    "cost_elim=lambda n: n**3\n",
    "cost_direct=lambda n: sp.factorial(n)\n",
    "\n",
    "n=np.linspace(1,20,100)\n",
    "plt.semilogy(n,cost_elim(n),'g',label='Elimination: $O(n^3)$')\n",
    "plt.semilogy(n,cost_direct(n),'r',label='Direct: $O(n!)$')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('system size, n')\n",
    "plt.ylabel('approximate number of operations')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The disastrous scalability of the direct method is evident! A 100 x 100 matrix is fairly common in calculus problems (in later weeks). Naively calculating the inverse using the pen-and-paper algorithm that we learn in linear algebra classes would take over $100!\\approx 10^{157}$ operations. Even with modern superfast computers, these are astronomically long times. However, Gauss elimination and related methods take roughly $100^3=1000000$ operations, which a modern laptop can easily do in a few seconds.\n",
    "\n",
    "So, to summarize: always use elimination methods for big matrix problems. NEVER INVERT DIRECTLY. We will learn how to cleverly use elimination strategies to determine the inverse (if you needed to) in the practice problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='inbuilt'></a>\n",
    "\n",
    "\n",
    "\n",
    "## (4.2) Inbuilt Python Routines\n",
    "\n",
    "By now, we know enough about python to not be surprised to learn that many of these functions are available in efficiently packaged forms that we can directly use. We briefly saw in Chapter 2 that `numpy` has a submodule `linalg` for linear algebra. This submodule contains a whole range of convenient linear algebra tools, including solutions of linear systems of equations.\n",
    "\n",
    "<a id='solve'></a>\n",
    "\n",
    "\n",
    "\n",
    "### Solving Linear Systems: `linalg.solve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [-2.]\n",
      " [ 3.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "\n",
    "A=np.array([[4,-2,1],[-2,4,-2],[1,-2,4]],dtype=float)\n",
    "b=np.array([[11],[-16],[17]])\n",
    "\n",
    "x=la.solve(A,b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a convenient 'black-box' approach, meaning we don't know what's happening inside the `solve` routine. Our home-made functions `GaussPiv` or `GaussJ` would do the same thing at about the same practical efficiency and speed, and by now you we every step in the process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='linalg'></a>\n",
    "\n",
    "\n",
    "\n",
    "### Fast and Easy Linear Algebra\n",
    "\n",
    "`numpy.linalg.solve` contains other useful functions. For example, finding the inverse of a matrix is closely related to elimination: see practice problem 4 to develop your own function to evaluate the inverse of a matrix. The inbuilt function `inv` does the same job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333333, 0.16666667, 0.        ],\n",
       "       [0.16666667, 0.41666667, 0.16666667],\n",
       "       [0.        , 0.16666667, 0.33333333]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.inv(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful inbuilt function in this submodule is `eig`: it returns the eigenvalues (as a row vector) and the eigenvectors packed into a matrix (so that each column is the corresponding eigenvector):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.37228132, 3.        , 1.62771868]),\n",
       " array([[-5.41774320e-01,  7.07106781e-01,  4.54401349e-01],\n",
       "        [ 6.42620551e-01,  2.51964435e-16,  7.66184591e-01],\n",
       "        [-5.41774320e-01, -7.07106781e-01,  4.54401349e-01]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.eig(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`linalg` also has inbuilt functions to evaluate common matrix manipulations like QR decomposition, singular-value decomposition, Cholesky decomposition, determinants, and norms. Details and usage can be found at the [official numpy documentation](https://numpy.org/doc/stable/reference/routines.linalg.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='exer'></a>\n",
    "\n",
    "\n",
    "\n",
    "## Practice Problems\n",
    "\n",
    "(1,2) As described in the tutorial text, create packaged functions for Gauss elimination with pivoting, and the Gauss-Jordan elimination. These functions should take an $n \\times n$ matrix and an $n \\times 1$ column vector as input, and give the solution to the linear system as output.\n",
    "\n",
    "Some linear systems have no solution or infinite solutions (recall Cramer's rule from linear algebra). How would you check for these cases and prevent a singular solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gauss with pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gauss-Jordan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) A common matrix type that comes up in solving boundary-value problems (week 9/10) are banded systems. These matrices only have terms along specific diagonal 'bands'. The simplest is the [tridiagonal matrix](https://en.wikipedia.org/wiki/Tridiagonal_matrix), in which the only non-zero entries are along the main diagonal and the adjacent diagonal lines:\n",
    "$$\\begin{bmatrix} t_{00} & t_{01} &  &  & \\\\ t_{10}& t_{11} & t_{12} & &  \\\\ & t_{21} & \\ddots &\\ddots& \\\\& & \\ddots & \\ddots &t_{n-2,n-1} \\\\& &  & t_{n-1,n-2} &t_{n-1,n-1}\\end{bmatrix} \\begin{bmatrix} x_0 \\\\ x_1 \\\\ .\\\\.\\\\.\\\\ x_{n-1}  \\end{bmatrix}= \\begin{bmatrix} b_0 \\\\ b_1 \\\\ .\\\\.\\\\.\\\\ b_{n-1}  \\end{bmatrix}$$\n",
    "\n",
    "Running loops through row and columns filled mostly with zeros is inefficient, so adapt the Gauss-Jordan elimination to only have to loop through the three diagonal lines. \n",
    "\n",
    "_Non-coding assignment: Try to roughly estimate the computational cost of such a tridiagonal solver. How much faster would this code ideally be for a $100 \\times 100$ tridiagonal matrix compared to standard Gauss-Jordan elimination_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tridiag solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) How would you evaluate the inverse of a $3\\times 3$ matrix using three calls to the Gauss-Jordan function. Remember that naively calculating the determinant (which is required for the 'standard' method to find the inverse) is computationally expensive. Think about what the definition of the inverse of a matrix and how it relates to the identity matrix. Could you recast this definition as three different linear systems...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Use a simple $3 \\times 3$ matrix to perform every step of the Gauss-Jordan elimination manually, and keep track of how the determinant of the matrix changes with each step. Using this knowledge, how would you code a function that calculates the determinant as you go throught the elimination process?\n",
    "\n",
    "How does row swapping (or pivoting) affect the determinant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
